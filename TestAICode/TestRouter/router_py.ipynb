{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f81673",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "Design a generic Python decorator @route_call that can be applied to instance methods, class methods, static methods, or standalone functions. This decorator should dynamically route the method call to one of two executors:\n",
    "\n",
    "- A LibraryExecutor (for local execution)\n",
    "- A ServiceExecutor (for remote/service execution)\n",
    "- The routing decision is based on attributes of the calling context (e.g., self.use_service).\n",
    "\n",
    "ðŸ“Œ Functional Requirements:\n",
    "- Dynamic Routing: Determine at runtime whether the function should be executed locally or via a simulated remote call.\n",
    "- Context Inspection: Automatically extract context (self, cls, etc.) for the decorator, regardless of whether it's applied to instance methods, class methods, static methods, or standalone functions.\n",
    "- LibraryExecutor Logic: \n",
    "  - Acts as a local call interceptor.\n",
    "  - If context.remote_user is available, modifies the functionâ€™s arguments (e.g., injects an audited_by value).\n",
    "  - Can restrict execution based on user (e.g., prevent \"guest\" from calling restricted functions).\n",
    "- ServiceExecutor Logic:\n",
    "  - Simulates a remote call to the function.\n",
    "  - If one of the arguments is a large list, splits it into batches.\n",
    "  - Uses a ThreadPoolExecutor to process batches concurrently.\n",
    "  - Merges and returns results from all batches.\n",
    "- Batching Policy:\n",
    "  - Configurable batch size.\n",
    "  - Automatically detects list arguments that are too large and need splitting.\n",
    "\n",
    "ðŸ§ª Sample Use Cases:\n",
    "- MyService.process_items(large_list) â€” routed to ServiceExecutor and batched.\n",
    "- MyService.update_data(record_id) â€” injected with audited_by = remote_user.\n",
    "- MyService.delete_data() â€” blocked if user is \"guest\".\n",
    "- @route_call works seamlessly on class/static methods and functions.\n",
    "\n",
    "### Bonus Points:\n",
    "- Clean, extensible design using strategy patterns (Executor interface).\n",
    "- Uses Python introspection to avoid requiring explicit metadata.\n",
    "- Modular and testable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c482b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0c6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "import concurrent.futures\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Abstract executor interface\n",
    "class Executor(ABC):\n",
    "    @abstractmethod\n",
    "    def execute(self, func: Callable, args: Tuple, kwargs: Dict[str, Any], context: Any = None) -> Any:\n",
    "        pass\n",
    "\n",
    "# Local execution implementation\n",
    "class LibraryExecutor(Executor):\n",
    "    def execute(self, func: Callable, args: Tuple, kwargs: Dict[str, Any], context: Any = None) -> Any:\n",
    "        # Add auditing if remote_user is available\n",
    "        if context and hasattr(context, 'remote_user'):\n",
    "            kwargs['audited_by'] = context.remote_user\n",
    "            \n",
    "            # Restrict guest users from certain operations\n",
    "            if context.remote_user == \"guest\" and func.__name__.startswith((\"delete\", \"remove\", \"drop\")):\n",
    "                raise PermissionError(f\"User '{context.remote_user}' is not allowed to perform {func.__name__}\")\n",
    "        \n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "# Service/Remote execution implementation\n",
    "class ServiceExecutor(Executor):\n",
    "    def __init__(self, batch_size: int = 100):\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def execute(self, func: Callable, args: Tuple, kwargs: Dict[str, Any], context: Any = None) -> Any:\n",
    "        # Identify large list arguments that need batching\n",
    "        batch_args = {}\n",
    "        for i, arg in enumerate(args):\n",
    "            if isinstance(arg, list) and len(arg) > self.batch_size:\n",
    "                batch_args[i] = arg\n",
    "        \n",
    "        for key, value in kwargs.items():\n",
    "            if isinstance(value, list) and len(value) > self.batch_size:\n",
    "                batch_args[key] = value\n",
    "        \n",
    "        # If no large lists, just execute normally\n",
    "        if not batch_args:\n",
    "            print(f\"Remote execution of {func.__name__} (no batching needed)\")\n",
    "            return func(*args, **kwargs)\n",
    "        \n",
    "        # Handle batched execution\n",
    "        print(f\"Remote execution of {func.__name__} with batching\")\n",
    "        return self._execute_batched(func, args, kwargs, batch_args)\n",
    "    \n",
    "    def _execute_batched(self, func: Callable, args: Tuple, kwargs: Dict[str, Any], batch_args: Dict) -> Any:\n",
    "        # Prepare batches\n",
    "        batch_jobs = []\n",
    "        \n",
    "        # Handle positional arguments\n",
    "        pos_batch_indices = [i for i in batch_args.keys() if isinstance(i, int)]\n",
    "        if pos_batch_indices:\n",
    "            # Get the largest list for determining batch count\n",
    "            largest_list_index = max(pos_batch_indices, key=lambda i: len(batch_args[i]))\n",
    "            largest_list = batch_args[largest_list_index]\n",
    "            batch_count = (len(largest_list) + self.batch_size - 1) // self.batch_size\n",
    "            \n",
    "            for batch_idx in range(batch_count):\n",
    "                start_idx = batch_idx * self.batch_size\n",
    "                end_idx = min(start_idx + self.batch_size, len(largest_list))\n",
    "                \n",
    "                # Create new args tuple for this batch\n",
    "                batch_args_tuple = list(args)\n",
    "                for i in pos_batch_indices:\n",
    "                    if start_idx < len(batch_args[i]):\n",
    "                        end_for_this_list = min(end_idx, len(batch_args[i]))\n",
    "                        batch_args_tuple[i] = batch_args[i][start_idx:end_for_this_list]\n",
    "                    else:\n",
    "                        batch_args_tuple[i] = []\n",
    "                \n",
    "                # Create a copy of kwargs\n",
    "                batch_kwargs = kwargs.copy()\n",
    "                \n",
    "                # Add job\n",
    "                batch_jobs.append((func, tuple(batch_args_tuple), batch_kwargs))\n",
    "        \n",
    "        # Handle keyword arguments (if no positional batching or additional keyword batching)\n",
    "        kw_batch_keys = [k for k in batch_args.keys() if isinstance(k, str)]\n",
    "        if kw_batch_keys and not pos_batch_indices:\n",
    "            # Get the largest list for determining batch count\n",
    "            largest_list_key = max(kw_batch_keys, key=lambda k: len(batch_args[k]))\n",
    "            largest_list = batch_args[largest_list_key]\n",
    "            batch_count = (len(largest_list) + self.batch_size - 1) // self.batch_size\n",
    "            \n",
    "            for batch_idx in range(batch_count):\n",
    "                start_idx = batch_idx * self.batch_size\n",
    "                end_idx = min(start_idx + self.batch_size, len(largest_list))\n",
    "                \n",
    "                # Create a copy of kwargs for this batch\n",
    "                batch_kwargs = kwargs.copy()\n",
    "                for key in kw_batch_keys:\n",
    "                    if start_idx < len(batch_args[key]):\n",
    "                        end_for_this_list = min(end_idx, len(batch_args[key]))\n",
    "                        batch_kwargs[key] = batch_args[key][start_idx:end_for_this_list]\n",
    "                    else:\n",
    "                        batch_kwargs[key] = []\n",
    "                \n",
    "                # Add job\n",
    "                batch_jobs.append((func, args, batch_kwargs))\n",
    "        \n",
    "        # Execute all batches in parallel\n",
    "        results = []\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(job[0], *job[1], **job[2]) for job in batch_jobs]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    if isinstance(result, list):\n",
    "                        results.extend(result)\n",
    "                    else:\n",
    "                        results.append(result)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Decorator factory\n",
    "def route_call(_func=None, *, batch_size=100):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            # Determine if this is an instance method, class method, or static method\n",
    "            context = None\n",
    "            is_instance_method = False\n",
    "            is_class_method = False\n",
    "            \n",
    "            if args:\n",
    "                # Check if this is an instance method call\n",
    "                if hasattr(args[0].__class__, func.__name__):\n",
    "                    method = getattr(args[0].__class__, func.__name__)\n",
    "                    # Check if the method on the class is the same function or a descriptor\n",
    "                    if (\n",
    "                        method is func \n",
    "                        or (hasattr(method, '__func__') and method.__func__ is func)\n",
    "                        or (inspect.ismethod(method) and method.__func__ is func)\n",
    "                    ):\n",
    "                        context = args[0]\n",
    "                        is_instance_method = True\n",
    "                \n",
    "                # Check if this is a class method call\n",
    "                if not is_instance_method and inspect.isclass(args[0]):\n",
    "                    method = getattr(args[0], func.__name__, None)\n",
    "                    if method and hasattr(method, '__func__') and method.__func__ is func:\n",
    "                        context = args[0]  # class itself becomes the context\n",
    "                        is_class_method = True\n",
    "            \n",
    "            # Determine which executor to use\n",
    "            use_service = False\n",
    "            if is_instance_method and hasattr(context, 'use_service'):\n",
    "                use_service = context.use_service\n",
    "            elif is_class_method and hasattr(context, 'use_service'):\n",
    "                use_service = context.use_service\n",
    "            \n",
    "            # Select executor based on context\n",
    "            executor = ServiceExecutor(batch_size=batch_size) if use_service else LibraryExecutor()\n",
    "            \n",
    "            # Execute with appropriate context and arguments\n",
    "            if is_instance_method:\n",
    "                # Skip the 'self' argument as it's the context\n",
    "                return executor.execute(func, args[1:], kwargs, context)\n",
    "            elif is_class_method:\n",
    "                # Skip the 'cls' argument as it's the context\n",
    "                return executor.execute(func, args[1:], kwargs, context)\n",
    "            else:\n",
    "                # For static methods and standalone functions, no special context handling\n",
    "                return executor.execute(func, args, kwargs)\n",
    "        \n",
    "        return wrapper\n",
    "    \n",
    "    # Support both @route_call and @route_call(batch_size=...)\n",
    "    if _func is None:\n",
    "        return decorator\n",
    "    else:\n",
    "        return decorator(_func)\n",
    "\n",
    "# Example usage classes and methods\n",
    "class MyService:\n",
    "    def __init__(self, use_service=False, remote_user=None):\n",
    "        self.use_service = use_service\n",
    "        self.remote_user = remote_user\n",
    "    \n",
    "    @route_call\n",
    "    def process_items(self, items):\n",
    "        print(f\"Processing {len(items)} items\")\n",
    "        return [item * 2 for item in items]\n",
    "    \n",
    "    @route_call\n",
    "    def update_data(self, record_id, data=None, **kwargs):\n",
    "        print(f\"Updating record {record_id} with {data}\")\n",
    "        print(f\"Additional kwargs: {kwargs}\")\n",
    "        return record_id\n",
    "    \n",
    "    @route_call\n",
    "    def delete_data(self, record_id):\n",
    "        print(f\"Deleting record {record_id}\")\n",
    "        return f\"Deleted {record_id}\"\n",
    "    \n",
    "    @classmethod\n",
    "    @route_call\n",
    "    def class_method_example(cls, value):\n",
    "        return f\"Class method processed {value}\"\n",
    "    \n",
    "    @staticmethod\n",
    "    @route_call\n",
    "    def static_method_example(value):\n",
    "        return f\"Static method processed {value}\"\n",
    "\n",
    "@route_call\n",
    "def standalone_function(value):\n",
    "    return f\"Standalone function processed {value}\"\n",
    "\n",
    "# Set a class attribute for class method routing\n",
    "MyService.use_service = False\n",
    "\n",
    "# Test the implementation\n",
    "if __name__ == \"__main__1\":\n",
    "    # Create instances with different configurations\n",
    "    local_service = MyService(use_service=False, remote_user=\"admin\")\n",
    "    remote_service = MyService(use_service=True, remote_user=\"user1\")\n",
    "    guest_service = MyService(use_service=False, remote_user=\"guest\")\n",
    "    \n",
    "    # Test instance methods\n",
    "    print(\"\\n-- Local service, instance method --\")\n",
    "    result1 = local_service.process_items([1, 2, 3])\n",
    "    print(f\"Result: {result1}\")\n",
    "    \n",
    "    print(\"\\n-- Remote service with batching, instance method --\")\n",
    "    large_list = list(range(250))\n",
    "    result2 = remote_service.process_items(large_list)\n",
    "    print(f\"Result length: {len(result2)}\")\n",
    "    \n",
    "    print(\"\\n-- Local service with auditing --\")\n",
    "    local_service.update_data(42, data={\"name\": \"Test\"})\n",
    "    \n",
    "    print(\"\\n-- Guest user attempting delete --\")\n",
    "    try:\n",
    "        guest_service.delete_data(99)\n",
    "    except PermissionError as e:\n",
    "        print(f\"Expected error: {e}\")\n",
    "    \n",
    "    # Test class and static methods\n",
    "    print(\"\\n-- Class method --\")\n",
    "    result3 = MyService.class_method_example(\"test\")\n",
    "    print(f\"Result: {result3}\")\n",
    "    \n",
    "    print(\"\\n-- Static method --\")\n",
    "    result4 = MyService.static_method_example(\"test\")\n",
    "    print(f\"Result: {result4}\")\n",
    "    \n",
    "    # Test standalone function\n",
    "    print(\"\\n-- Standalone function --\")\n",
    "    result5 = standalone_function(\"test\")\n",
    "    print(f\"Result: {result5}\")\n",
    "    \n",
    "    # Change class attribute and test class method routing\n",
    "    print(\"\\n-- Class method with service enabled --\")\n",
    "    MyService.use_service = True\n",
    "    result6 = MyService.class_method_example(\"test\")\n",
    "    print(f\"Result: {result6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd056c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22093e74",
   "metadata": {},
   "source": [
    "### Now change scope \n",
    "- decorate instance-method alone\n",
    "- use access policy : routing policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47cb9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "import concurrent.futures\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Access Policy Manager - determines routing based on context and function\n",
    "class AccessPolicyManager:\n",
    "    @staticmethod\n",
    "    def should_use_service(instance: Any, func_name: str, args: Tuple, kwargs: Dict[str, Any]) -> bool:\n",
    "        \"\"\"\n",
    "        Determines if a method call should be routed to service based on access policy.\n",
    "        \n",
    "        This method evaluates various conditions:\n",
    "        1. User roles and permissions\n",
    "        2. Resource type being accessed\n",
    "        3. Operation type (read, write, delete)\n",
    "        4. Data size and complexity\n",
    "        5. System load/capacity\n",
    "        \"\"\"\n",
    "        # Example implementation - can be expanded with more complex logic\n",
    "        \n",
    "        # Check if user has specific roles that require service execution\n",
    "        if hasattr(instance, 'remote_user'):\n",
    "            # Admin users might have direct library access for certain operations\n",
    "            if instance.remote_user == \"admin\" and not func_name.startswith(\"batch\"):\n",
    "                return False\n",
    "                \n",
    "            # Service users always go through service\n",
    "            if instance.remote_user.startswith(\"service_\"):\n",
    "                return True\n",
    "                \n",
    "            # Guest users use service for non-sensitive operations\n",
    "            if instance.remote_user == \"guest\" and not func_name.startswith((\"delete\", \"update\")):\n",
    "                return True\n",
    "        \n",
    "        # Check data size - large data operations go to service\n",
    "        for arg in args:\n",
    "            if isinstance(arg, list) and len(arg) > 100:\n",
    "                return True\n",
    "        \n",
    "        for value in kwargs.values():\n",
    "            if isinstance(value, list) and len(value) > 100:\n",
    "                return True\n",
    "        \n",
    "        # Default routing based on operation type\n",
    "        if func_name.startswith((\"get\", \"list\", \"search\")):\n",
    "            return False  # Read operations default to library\n",
    "        elif func_name.startswith((\"create\", \"update\", \"delete\", \"process\")):\n",
    "            return True   # Write/process operations default to service\n",
    "            \n",
    "        # Default to library execution\n",
    "        return False\n",
    "\n",
    "# Abstract executor interface\n",
    "class Executor(ABC):\n",
    "    @abstractmethod\n",
    "    def execute(self, func: Callable, instance: Any, args: Tuple, kwargs: Dict[str, Any]) -> Any:\n",
    "        pass\n",
    "\n",
    "# Local execution implementation\n",
    "class LibraryExecutor(Executor):\n",
    "    def execute(self, func: Callable, instance: Any, args: Tuple, kwargs: Dict[str, Any]) -> Any:\n",
    "        print(f\"Library execution: {func.__name__}\")\n",
    "        \n",
    "        # Add auditing if remote_user is available\n",
    "        if hasattr(instance, 'remote_user'):\n",
    "            kwargs['audited_by'] = instance.remote_user\n",
    "            \n",
    "            # Restrict guest users from certain operations\n",
    "            if instance.remote_user == \"guest\" and func.__name__.startswith((\"delete\", \"remove\", \"drop\")):\n",
    "                raise PermissionError(f\"User '{instance.remote_user}' is not allowed to perform {func.__name__}\")\n",
    "        \n",
    "        return func(instance, *args, **kwargs)\n",
    "\n",
    "# Service/Remote execution implementation\n",
    "class ServiceExecutor(Executor):\n",
    "    def __init__(self, batch_size: int = 100):\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def execute(self, func: Callable, instance: Any, args: Tuple, kwargs: Dict[str, Any]) -> Any:\n",
    "        print(f\"Service execution: {func.__name__}\")\n",
    "        \n",
    "        # Identify large list arguments that need batching\n",
    "        batch_args = {}\n",
    "        for i, arg in enumerate(args):\n",
    "            if isinstance(arg, list) and len(arg) > self.batch_size:\n",
    "                batch_args[i] = arg\n",
    "        \n",
    "        for key, value in kwargs.items():\n",
    "            if isinstance(value, list) and len(value) > self.batch_size:\n",
    "                batch_args[key] = value\n",
    "        \n",
    "        # If no large lists, just execute normally\n",
    "        if not batch_args:\n",
    "            print(f\"No batching needed\")\n",
    "            return func(instance, *args, **kwargs)\n",
    "        \n",
    "        # Handle batched execution\n",
    "        print(f\"Using batching with size {self.batch_size}\")\n",
    "        return self._execute_batched(func, instance, args, kwargs, batch_args)\n",
    "    \n",
    "    def _execute_batched(self, func: Callable, instance: Any, args: Tuple, kwargs: Dict[str, Any], batch_args: Dict) -> Any:\n",
    "        # Prepare batches\n",
    "        batch_jobs = []\n",
    "        \n",
    "        # Handle positional arguments\n",
    "        pos_batch_indices = [i for i in batch_args.keys() if isinstance(i, int)]\n",
    "        if pos_batch_indices:\n",
    "            # Get the largest list for determining batch count\n",
    "            largest_list_index = max(pos_batch_indices, key=lambda i: len(batch_args[i]))\n",
    "            largest_list = batch_args[largest_list_index]\n",
    "            batch_count = (len(largest_list) + self.batch_size - 1) // self.batch_size\n",
    "            \n",
    "            for batch_idx in range(batch_count):\n",
    "                start_idx = batch_idx * self.batch_size\n",
    "                end_idx = min(start_idx + self.batch_size, len(largest_list))\n",
    "                \n",
    "                # Create new args tuple for this batch\n",
    "                batch_args_tuple = list(args)\n",
    "                for i in pos_batch_indices:\n",
    "                    if start_idx < len(batch_args[i]):\n",
    "                        end_for_this_list = min(end_idx, len(batch_args[i]))\n",
    "                        batch_args_tuple[i] = batch_args[i][start_idx:end_for_this_list]\n",
    "                    else:\n",
    "                        batch_args_tuple[i] = []\n",
    "                \n",
    "                # Create a copy of kwargs\n",
    "                batch_kwargs = kwargs.copy()\n",
    "                \n",
    "                # Add job\n",
    "                batch_jobs.append((func, instance, tuple(batch_args_tuple), batch_kwargs))\n",
    "        \n",
    "        # Handle keyword arguments (if no positional batching or additional keyword batching)\n",
    "        kw_batch_keys = [k for k in batch_args.keys() if isinstance(k, str)]\n",
    "        if kw_batch_keys and not pos_batch_indices:\n",
    "            # Get the largest list for determining batch count\n",
    "            largest_list_key = max(kw_batch_keys, key=lambda k: len(batch_args[k]))\n",
    "            largest_list = batch_args[largest_list_key]\n",
    "            batch_count = (len(largest_list) + self.batch_size - 1) // self.batch_size\n",
    "            \n",
    "            for batch_idx in range(batch_count):\n",
    "                start_idx = batch_idx * self.batch_size\n",
    "                end_idx = min(start_idx + self.batch_size, len(largest_list))\n",
    "                \n",
    "                # Create a copy of kwargs for this batch\n",
    "                batch_kwargs = kwargs.copy()\n",
    "                for key in kw_batch_keys:\n",
    "                    if start_idx < len(batch_args[key]):\n",
    "                        end_for_this_list = min(end_idx, len(batch_args[key]))\n",
    "                        batch_kwargs[key] = batch_args[key][start_idx:end_for_this_list]\n",
    "                    else:\n",
    "                        batch_kwargs[key] = []\n",
    "                \n",
    "                # Add job\n",
    "                batch_jobs.append((func, instance, args, batch_kwargs))\n",
    "        \n",
    "        # Execute all batches in parallel\n",
    "        results = []\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            # Notice we're passing instance as the first arg to each function\n",
    "            futures = [executor.submit(job[0], job[1], *job[2], **job[3]) for job in batch_jobs]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    if isinstance(result, list):\n",
    "                        results.extend(result)\n",
    "                    else:\n",
    "                        results.append(result)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Decorator factory with access policy-based routing\n",
    "def route_call(_func=None, *, batch_size=100):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            # Use the policy manager to determine routing\n",
    "            use_service = AccessPolicyManager.should_use_service(\n",
    "                instance=self, \n",
    "                func_name=func.__name__,\n",
    "                args=args,\n",
    "                kwargs=kwargs\n",
    "            )\n",
    "            \n",
    "            # Select executor based on policy decision\n",
    "            executor = ServiceExecutor(batch_size=batch_size) if use_service else LibraryExecutor()\n",
    "            \n",
    "            # Execute with instance as the context\n",
    "            return executor.execute(func, self, args, kwargs)\n",
    "        \n",
    "        return wrapper\n",
    "    \n",
    "    # Support both @route_call and @route_call(batch_size=...)\n",
    "    if _func is None:\n",
    "        return decorator\n",
    "    else:\n",
    "        return decorator(_func)\n",
    "\n",
    "# Example usage class with instance methods\n",
    "class MyService:\n",
    "    def __init__(self, remote_user=None):\n",
    "        self.remote_user = remote_user\n",
    "    \n",
    "    @route_call\n",
    "    def process_items(self, items):\n",
    "        print(f\"Processing {len(items)} items\")\n",
    "        return [item * 2 for item in items]\n",
    "    \n",
    "    @route_call\n",
    "    def get_items(self, filter_value=None):\n",
    "        print(f\"Getting items with filter: {filter_value}\")\n",
    "        return [1, 2, 3] if filter_value else [1, 2, 3, 4, 5]\n",
    "    \n",
    "    @route_call\n",
    "    def update_data(self, record_id, data=None, **kwargs):\n",
    "        print(f\"Updating record {record_id} with {data}\")\n",
    "        print(f\"Additional kwargs: {kwargs}\")\n",
    "        return record_id\n",
    "    \n",
    "    @route_call\n",
    "    def delete_data(self, record_id):\n",
    "        print(f\"Deleting record {record_id}\")\n",
    "        return f\"Deleted {record_id}\"\n",
    "    \n",
    "    @route_call\n",
    "    def batch_process(self, items):\n",
    "        print(f\"Batch processing {len(items)} items\")\n",
    "        return [f\"Processed {item}\" for item in items]\n",
    "\n",
    "# Test the implementation\n",
    "if __name__ == \"__main__1\":\n",
    "    # Create instances with different user types\n",
    "    admin_service = MyService(remote_user=\"admin\")\n",
    "    service_user = MyService(remote_user=\"service_account1\")\n",
    "    guest_user = MyService(remote_user=\"guest\")\n",
    "    \n",
    "    # Test with admin user\n",
    "    print(\"\\n-- Admin user tests --\")\n",
    "    result1 = admin_service.process_items([1, 2, 3])  # Should use library (small list)\n",
    "    print(f\"Result: {result1}\")\n",
    "    \n",
    "    large_list = list(range(250))\n",
    "    result2 = admin_service.process_items(large_list)  # Should use service (large list)\n",
    "    print(f\"Result length: {len(result2)}\")\n",
    "    \n",
    "    result3 = admin_service.get_items()  # Should use library (read operation)\n",
    "    print(f\"Result: {result3}\")\n",
    "    \n",
    "    result4 = admin_service.batch_process([1, 2, 3])  # Should use service (batch operation)\n",
    "    print(f\"Result: {result4}\")\n",
    "    \n",
    "    # Test with service user\n",
    "    print(\"\\n-- Service user tests --\")\n",
    "    result5 = service_user.get_items(\"test\")  # Should use service regardless of operation\n",
    "    print(f\"Result: {result5}\")\n",
    "    \n",
    "    # Test with guest user\n",
    "    print(\"\\n-- Guest user tests --\")\n",
    "    result6 = guest_user.get_items()  # Should use service\n",
    "    print(f\"Result: {result6}\")\n",
    "    \n",
    "    print(\"\\n-- Guest attempting delete --\")\n",
    "    try:\n",
    "        guest_user.delete_data(99)  # Should raise permission error\n",
    "    except PermissionError as e:\n",
    "        print(f\"Expected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69776187",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_preppyenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
